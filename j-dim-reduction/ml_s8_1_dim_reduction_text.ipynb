{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634fc08b-4970-41c4-b99b-6fddaaa9ecd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dimensionality Reduction\n",
    "### on text data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "073bab52-fe2e-4d8e-86cf-fff52a9c120c",
   "metadata": {},
   "source": [
    "Dimensionality Reduction, in Python with Scikit-learn\n",
    "\n",
    "The dataset is part of the [Youth Mental Health Narratives](https://www.drivendata.org/competitions/group/cdc-narratives/) project.\n",
    "\n",
    "<br>\n",
    "@Ricardo Almeida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db77e6b1-b19f-43b3-bf8e-f5c4569cebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44d909-eeb3-4d52-b83c-ae2458891ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2b353-6b8e-4c9d-b1da-cba072ed6c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = nltk.download('stopwords', quiet=True)\n",
    "_ = nltk.download('wordnet', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a990ae40-6113-4426-ab89-10d83cb2a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column = 'NarrativeLE'\n",
    "\n",
    "RANDOM_SEED = 87987"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f2c2e-4f96-4087-a119-815d02bb30a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfc93b1-4573-4393-94a3-49777622b4d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Youth Mental Health Narratives dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f43f3bb-9370-4189-9e70-12a45e38c9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/features_Z140Hep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50986a0b-7dc8-481d-8294-ddbd1e2349b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132dae9c-bfae-429d-80af-fc8f8571ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[text_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26fb6c7-814d-4ec8-b090-8568a2d99747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007660e-bf4e-4321-814c-07a04b33247f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pre-processing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ab4cf-09ba-4ae0-b19b-db05e7de687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0fb66-baf1-4460-93ce-91c51935e34e",
   "metadata": {},
   "source": [
    "Applying these transformations:\n",
    "\n",
    "- Remove punctuation\n",
    "- Blacklist removal: removing specific words\n",
    "- Tokenization: splits the text into individual words (tokens)\n",
    "- Lemmatization: reduces words to their base, dictionary form\n",
    "- Lowercasing: converting all text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f96d10-6af6-4c72-ad7d-2cee022cf081",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[text_column] = df[text_column].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732606d5-bd2c-4353-9271-54120a6f9949",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_blacklist = ['v', 'v1', 'v2', 'xxxx', 'xx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e590c-bc50-49c5-b760-910aed4174b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process text\n",
    "def process_text(text):\n",
    "\n",
    "    # Tokenize the text (split text into words, remove punctuation)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    lemmatizer = WordNetLemmatizer()    \n",
    "    stop_words_set = set(stopwords.words('english'))\n",
    "    processed_tokens = [\n",
    "        lemmatizer.lemmatize(token)  # Reduce words to their base or dictionary form\n",
    "        for token in tokens\n",
    "        if token not in stop_words_set and not token.isnumeric()\n",
    "    ]\n",
    "    # remove blacklisted words\n",
    "    processed_tokens = [token for token in processed_tokens if token not in word_blacklist]\n",
    "    # remove tokens starting with a number or other character (include only alphabetic)\n",
    "    processed_tokens = [token for token in processed_tokens if token[0].isalpha()]\n",
    "    \n",
    "    return processed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5d1c8-1516-4d78-81b4-396fa6597a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text preprocessing\n",
    "\n",
    "df['tokens'] = df[text_column].apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf2ee4-cf32-493d-9eef-da6e9a681d5a",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a53fb9-4aa7-4409-b1c4-f4c69d81e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten list to strings\n",
    "df['token_str'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# One-hot encoding\n",
    "vectorizer = CountVectorizer(binary=True)  # binary=True ensures one-hot encoding\n",
    "one_hot_encoded = vectorizer.fit_transform(df['token_str'])\n",
    "\n",
    "# Convert to DataFrame\n",
    "one_df = pd.DataFrame(one_hot_encoded.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d2074-e19a-4d0d-b09f-4f2f2fe4038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57fea1-de61-48b3-811c-865f29423d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dimensionality\\nNr. words = {one_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce17374-5048-4cd0-872b-0a351ffaaec0",
   "metadata": {},
   "source": [
    "### Dimensionality reduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c173ea7a-59df-413b-8e17-750d5bd7a432",
   "metadata": {},
   "source": [
    "#### Task #1\n",
    "\n",
    "*Task*: Apply t-SNE, reducing the data on `one_df` to **2 dimensions** for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611958a3-82dd-4953-a6af-4508bc9a2c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE with 2 components\n",
    "\n",
    "# define the t-SNE model\n",
    "tsne = ...\n",
    "\n",
    "# perform the transformation on 'one_df' dataframe\n",
    "reduced_data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18146a9-66fd-46fb-8189-7e54859ed1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame for visualization\n",
    "reduced_df = pd.DataFrame(reduced_data, columns=['Dimension 1', 'Dimension 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dcb0f8-97db-4ec9-b973-28eb72bee928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of data, projected into a 2D space\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='Dimension 1', y='Dimension 2', data=reduced_df, alpha=0.7, s=10)\n",
    "plt.title(\"t-SNE Visualization of One-Hot Encoded Word Occurrences\", fontsize=14)\n",
    "plt.xlabel(\"Dimension 1\", fontsize=12)\n",
    "plt.ylabel(\"Dimension 2\", fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7dffcc-7ae6-413e-8ce2-ab7aef57bf22",
   "metadata": {},
   "source": [
    "#### Task #2\n",
    "\n",
    "*Task*: Apply t-SNE, reducing the data on `one_df` to **3 dimensions** for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce3b1e-c537-44ec-b40e-38784a522ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE with 3 components\n",
    "\n",
    "# define the t-SNE model\n",
    "tsne = ...\n",
    "\n",
    "# perform the transformation on 'one_df' dataframe\n",
    "reduced_data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f222bd-be24-4914-b4c3-54a74082d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for visualization\n",
    "reduced_df = pd.DataFrame(reduced_data, columns=['Dimension 1', 'Dimension 2', 'Dimension 3'])\n",
    "\n",
    "# Include the original words\n",
    "reduced_df['words'] = df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb4887-f63f-42e6-8987-06c21731b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive 3D visualization, using Plotly\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    reduced_df,\n",
    "    x='Dimension 1',\n",
    "    y='Dimension 2',\n",
    "    z='Dimension 3',\n",
    "    hover_name='words',\n",
    "    title=\"Interactive 3D t-SNE Visualization\",\n",
    "    opacity=0.7\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800,  # Set the width\n",
    "    height=600,  # Set the height\n",
    "    title_font=dict(size=20),  # Adjust the title font size\n",
    ")\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
