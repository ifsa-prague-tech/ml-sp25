{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634fc08b-4970-41c4-b99b-6fddaaa9ecd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Recurrent Neural Networks\n",
    "## for sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec98632-ceea-438d-8e2b-64de56d6cf21",
   "metadata": {},
   "source": [
    "Source:\n",
    "- Keras.io documentation\n",
    "- \"Sentiment Analysis using Keras & LSTM\" @ Medium\n",
    "\n",
    "Title: Bidirectional LSTM on IMDB\n",
    "\n",
    "Description: Train a 2-layer bidirectional LSTM on the IMDB movie review sentiment classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66a9e0-7f33-4151-b94c-541192b91d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fe647b-9762-4024-bbf5-4f2409fdd3d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "from keras.datasets import imdb\n",
    "from keras.layers import BatchNormalization, Dense, Dropout, Embedding, Flatten, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.utils import plot_model, to_categorical, pad_sequences\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a571d1ae-fe92-4d62-a9b6-e348eb2cb501",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b1b9d-ce9a-4d67-b5f2-dfc3cd322fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 5000  # Only consider the top 5k words\n",
    "input_length = 200  # Only consider the first 200 words of each movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed1f794-3347-4cf2-b801-6057ceec524f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_history(train_hist):\n",
    "    pd.DataFrame(train_hist).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f2c2e-4f96-4087-a119-815d02bb30a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8b37f1-530a-4437-b4ff-67f06ec05525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Load the IMDB movie review sentiment data\n",
    "# Load the data, already split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155d500-0eb3-4b2d-b940-fe06da4b9d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Train size: {x_train.shape[0]}\")\n",
    "print(f\"Test size:  {x_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc40aacb-d91c-4660-b191-7a14fb41bcb4",
   "metadata": {},
   "source": [
    "Labels:\n",
    "- 0 (negative review) or\n",
    "- 1 (positive review)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0fea65-096d-4b56-8b2e-0b96011fa015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6571f93e-b3c1-4d6f-97db-e9bfd0128518",
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEW_INDEX = 2\n",
    "\n",
    "print(x_train[REVIEW_INDEX])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5351f11d-1387-475f-a715-cce65ee46ca3",
   "metadata": {},
   "source": [
    "These are vector representations of word indexes. We need to pad the sequence to a maximum of 500 words. For that Keras provides us with the pad_sequences method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e550638c-019b-4d98-8981-f7e8d57e797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pad_sequence to standardize sequence length:\n",
    "# this will truncate sequences longer than 200 words and zero-pad sequences shorter than 200 words.\n",
    "x_train = pad_sequences(x_train, maxlen=input_length)\n",
    "x_test = pad_sequences(x_test, maxlen=input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56bca06-292b-4713-9e97-af4de40dbd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[REVIEW_INDEX])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa746de-6960-4c3c-bca1-0689785d4eec",
   "metadata": {},
   "source": [
    "Now we need to build a word_to_id dictionary so that these indexes can be transformed into words for further analysis. In the dictionary, we will provide PAD token to index 0, START token to index 1, and UNK token to index 2. So we have to shift the default indexes by 3 to adjust these tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f581b08-fd89-4b85-80ce-20b0763dea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = imdb.get_word_index()\n",
    "word_to_id = {k:(v+3) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7c4541-533f-4d20-a6ec-a45f7e9874e7",
   "metadata": {},
   "source": [
    "After building word_to_it we need to id_to_word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3a10d-7727-43a6-9bf8-fde3a7c9cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word = {idx:word for word, idx in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d235014-cc1d-481a-9b57-f2166093f75f",
   "metadata": {},
   "source": [
    "**Convertion examples**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0b4fbe-8ab2-4cca-973b-5cf891c2569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f653597-5ead-47d6-bef1-5bbd4e8e0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = [id_to_word[id] for id in x_train[REVIEW_INDEX]]\n",
    "\n",
    "print(\" \".join(decoded_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5305fb66-b871-4588-a4a5-edaf6c9d3a95",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc059a3-975b-48cb-b1bd-635fa1170ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db268be3-aa69-4a62-979f-4a71f10a6d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a LSTM model for sentiment (binary) classification\n",
    "### YOUR CODE HERE:\n",
    "\n",
    "model = Sequential([\n",
    "    Input((...,)),\n",
    "    Embedding(top_words, embedding_vector_length),\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8389228e-4f05-4ddd-98b2-c306ebf4c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921812a0-2785-45a8-b9c9-5e6698a00dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc7956-abc2-4a1a-9da8-d8b3fb3b4dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "batch_size = 64\n",
    "\n",
    "trained = model.fit(x_train, y_train, \n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc4c977-f28a-4ee9-98b4-6e5c7af2363b",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49babfe0-3429-4b57-bcf1-412c2bdcb4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history(trained.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe938cd-0e16-483d-9965-1e2551865864",
   "metadata": {},
   "source": [
    "### Predict sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764551e-2cde-4ceb-8a52-db9f68bd2599",
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEW_INDEX = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a606db36-7d4d-450a-8884-648d3d7cba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = [id_to_word[id] for id in x_train[REVIEW_INDEX]]\n",
    "\n",
    "print(\" \".join(decoded_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079059d5-61e8-40e1-ac6f-8c68fad3d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_review = np.array([x_train[REVIEW_INDEX]])\n",
    "\n",
    "my_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4706943b-d43e-4dbf-8508-ec008a6c7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classify this review (`my_review`) in terms of sentiment\n",
    "### YOUR CODE HERE:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef29bd2-a8a9-4d7a-8056-80900d34398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Given now the following review text, transform this input and predict sentiment\n",
    "\n",
    "my_review_text = \"One of the finest films made in recent years.\"\n",
    "\n",
    "my_review_vec = []\n",
    "for word in my_review_text.split(\" \"):\n",
    "    if word[-1] == \".\":\n",
    "        word = word[:-1]\n",
    "    my_review_vec.append(word_to_id[str.lower(word)])\n",
    "\n",
    "my_review_vec = pad_sequences([my_review_vec], input_length)\n",
    "\n",
    "\n",
    "### YOUR CODE HERE:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167c10b-8e76-4b65-80d9-f2a2cf4716b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2f4f8-e613-4c87-9cb0-7dca8613c6af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
